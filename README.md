# David Markham
# Fundamentals of Data Analytics Project - September 2019
# G.M.I.T. 
# Lecturer: Ian McLoughlin 


## Project containing a Jupyter Notebook, describing the statistics, plots, and relationships between the variables within the well known Tips Data-set.

## Topic: The Tips Data-Set

![download](https://user-images.githubusercontent.com/47174160/67091657-22f6ac80-f1a5-11e9-9474-680c86e77c6f.jpg) (Monster.com, 2019) 

## This project required me to research the well known Tips data-set, provide my own analysis of it and describe what kind of relationships were there between the variables.

I will be using a Jupyter Notebook to illustrate my findings, and libraries such as Pandas and SeaBorn to illustrate my findings. Jupyter Notebook's are very powerful tools in terms of versatility, shareable and visualization.

My findings will be demonstrated by tables, graphs, histograms, scatter-plots, and other statistical tools. 

# Contents 
1. **Getting Started** 
2. **Software need for this project.** 
3. **Project Plan and purpose.** 
4. **What's involved when investigating a data set and how Jupyter Notebook can be used as a tool.**
5. **What is the TIPS Data Set**
6. **My Research and Investigation**
7. **Findings**
8. **Bibliography**

## 1. Getting Started

When investigating data four steps to follow can be as follows;

**1. Question**: What are you trying to resolve or achieve?

**2. Analyze**: What tools are you going to use to present your findings?

**3. Investigate**: Research and investigate the problem/sector you are trying to extract data from.

**4. Repeat**: Keep repeating the process until you resolve the problem and present your findings.

Data can be an excellent resource when trying to predict, forecast, improve decision-making or gain a competitive advantage. When investigating a data set you ask yourself what you want to get from it? What is the sole purpose of it, and will pulling data answer the problem you want to solve correctly?

An excellent way of aiding in your investigations is by displaying results via graphs, scatter plots etc, which can be done by using the Pandas and SeaBorn libraries. Machine learning is about making predictions. This will display data and explore for eg. weekly, monthly, quarterly or yearly trends based on what you are looking for.

## 2. Software needed for this project.

What software you will need to install to to get this project started.


- You will need to download Anaconda, and a command line. I will be using Commander.
- Create a Git Repository on Github, and clone it down to your terminal. 
- CD in the folder you just created on Github. 
- Jupyter Notebook will be displayed in your browser, when you type Juypter Notebook on your command line. From there you create a new Notebook, which we will be using to display our code and findings, and you're all set to go. 

## 3. Project Plan

To start with we will be going through what is involved when setting out to investigate a data set, and how you can back up arguments using scripts of code through Jupyter Notebook, certain libraries which will illustrate and back up your findings.

The purpose of this project is to gain skills using Jupyter Notebook, how to use libraries to display data visualization, statistics, and to improve my skills in machine learning. We will be using the Tips data-set to demonstrate our findings.

Using Jupyter Notebook I will explain my arguments and findings, and attached will be graphs, scatter-plots and other visualization which will be outputted from Pandas and SeaBorn libraries in my Jupyter Notebook. Along with the above data included will be screenshots of my work in the ReadMe, and various other techniques explained, which I used to demonstrate my findings. Finally I will provide a summary and draw my conclusion of the data set.








